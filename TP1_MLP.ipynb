{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1 MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2snH21SqsQA"
      },
      "source": [
        "***PARTE II***\n",
        "\n",
        "A continuación se repiten los pasos realizados en la Parte I utilizando el modelo MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOZ7wjugrmfo"
      },
      "source": [
        "Nuevamente se cargan las librerías a utilizar en esta sección."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKYNy5FegqbS"
      },
      "source": [
        "#Librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfiZs5pagNv-"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from string import punctuation\n",
        "from termcolor import colored\n",
        "from collections import Counter\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP5DinMrgxQ5"
      },
      "source": [
        "#Cargar datos de Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiNAmtIAr4Yf"
      },
      "source": [
        "Luego se prosigue cargando los datos desde kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "KCEPGfI6gwRv",
        "outputId": "b3f51f68-c210-436d-e938-ba566bdbacdc"
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1470810-b767-4820-ab29-2c9d4d9fe3af\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1470810-b767-4820-ab29-2c9d4d9fe3af\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"amaliaoxandaberro\",\"key\":\"dc3caded742346409c8426f0109c18a1\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYYziCDehX9i",
        "outputId": "7b849143-bf3e-4107-9781-3047f08adea9"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle competitions download -c sesgos-en-el-dataset-de-snli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test_data.hdf5.zip to /content\n",
            "  0% 0.00/200k [00:00<?, ?B/s]\n",
            "100% 200k/200k [00:00<00:00, 61.6MB/s]\n",
            "Downloading train_data.hdf5.zip to /content\n",
            " 98% 25.0M/25.6M [00:00<00:00, 69.6MB/s]\n",
            "100% 25.6M/25.6M [00:00<00:00, 85.1MB/s]\n",
            "Downloading submission_sample.csv to /content\n",
            "  0% 0.00/152k [00:00<?, ?B/s]\n",
            "100% 152k/152k [00:00<00:00, 46.0MB/s]\n",
            "Downloading valid_data.hdf5.zip to /content\n",
            "  0% 0.00/440k [00:00<?, ?B/s]\n",
            "100% 440k/440k [00:00<00:00, 133MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC4_qf6nhc7U",
        "outputId": "e7a1aa5c-dbe5-4c51-9352-2de92cc69096"
      },
      "source": [
        "!unzip test_data.hdf5.zip\n",
        "!unzip train_data.hdf5.zip\n",
        "!unzip valid_data.hdf5.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test_data.hdf5.zip\n",
            "  inflating: test_data.hdf5          \n",
            "Archive:  train_data.hdf5.zip\n",
            "  inflating: train_data.hdf5         \n",
            "Archive:  valid_data.hdf5.zip\n",
            "  inflating: valid_data.hdf5         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HuolYwthf0U"
      },
      "source": [
        "df_train = pd.read_hdf(\"/content/train_data.hdf5\")\n",
        "df_valid = pd.read_hdf(\"/content/valid_data.hdf5\")\n",
        "df_test = pd.read_hdf(\"/content/test_data.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNn13PtJhj1n"
      },
      "source": [
        "text_train = df_train[\"text\"].tolist()\n",
        "labels_train = df_train[\"gold_label\"].tolist()\n",
        "\n",
        "text_valid = df_valid[\"text\"].tolist()\n",
        "labels_valid = df_valid[\"gold_label\"].tolist()\n",
        "\n",
        "text_test = df_test[\"text\"].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPKF607qwmcq"
      },
      "source": [
        "#CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7CGFYZpxYBR"
      },
      "source": [
        "A continuación se utiliza el vectorizador Count Vectorizer para luego crear el modelo de MLP. Buscando llegar al mejor resultado se realizaron varios modelos modificando cada vez las distintas variables. En el caso del vectorizador, se cambiaron los parámetros min_df, max_df y ngram_range, pero también se cambiaron la cantidad de capas, la cantidad de neuronas por capa, la función de activación, batch size, epochs, learning rate y optimizador utilizado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g2xXpa7kljy"
      },
      "source": [
        "cv = CountVectorizer(min_df=100, max_df = 0.8, ngram_range = (1,1))\n",
        "cv_train = cv.fit_transform(text_train)\n",
        "cv_valid = cv.transform(text_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViF-v6MXwtCw"
      },
      "source": [
        "#Modelo MLP\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RgBAZF6lOYf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape = (cv_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(5, input_shape = (cv_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(3, activation=\"softmax\", input_shape = (cv_train.shape[1],)))\n",
        "opt = SGD(learning_rate=0.1)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer= opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6WSWDlHhWZm"
      },
      "source": [
        "ohe = OneHotEncoder()\n",
        "ohe.fit(np.array(labels_train).reshape(-1,1))\n",
        "labels_train_enc = ohe.transform(np.array(labels_train).reshape(-1,1))\n",
        "labels_val_enc = ohe.transform(np.array(labels_valid).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8cZo7lXhcFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2356dd6f-ed2d-4ad6-ed2b-4fee68f62b69"
      },
      "source": [
        "#callback = EarlyStopping(monitor='val_accuracy', patience=7, min_delta=0.000001)\n",
        "\n",
        "model.fit(x=cv_train.toarray(), y = labels_train_enc.toarray(), batch_size = 256, validation_data = (cv_valid.toarray(), labels_val_enc.toarray()),  verbose=1, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2146/2146 [==============================] - 16s 7ms/step - loss: 0.9633 - accuracy: 0.5593 - val_loss: 0.8694 - val_accuracy: 0.6116\n",
            "Epoch 2/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8606 - accuracy: 0.6145 - val_loss: 0.8456 - val_accuracy: 0.6240\n",
            "Epoch 3/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8493 - accuracy: 0.6206 - val_loss: 0.8420 - val_accuracy: 0.6223\n",
            "Epoch 4/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8462 - accuracy: 0.6218 - val_loss: 0.8407 - val_accuracy: 0.6250\n",
            "Epoch 5/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8450 - accuracy: 0.6221 - val_loss: 0.8399 - val_accuracy: 0.6251\n",
            "Epoch 6/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8445 - accuracy: 0.6221 - val_loss: 0.8394 - val_accuracy: 0.6250\n",
            "Epoch 7/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8441 - accuracy: 0.6220 - val_loss: 0.8398 - val_accuracy: 0.6257\n",
            "Epoch 8/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8439 - accuracy: 0.6224 - val_loss: 0.8394 - val_accuracy: 0.6244\n",
            "Epoch 9/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8438 - accuracy: 0.6221 - val_loss: 0.8394 - val_accuracy: 0.6267\n",
            "Epoch 10/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8436 - accuracy: 0.6223 - val_loss: 0.8397 - val_accuracy: 0.6256\n",
            "Epoch 11/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8435 - accuracy: 0.6226 - val_loss: 0.8390 - val_accuracy: 0.6235\n",
            "Epoch 12/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8435 - accuracy: 0.6224 - val_loss: 0.8393 - val_accuracy: 0.6280\n",
            "Epoch 13/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8434 - accuracy: 0.6225 - val_loss: 0.8394 - val_accuracy: 0.6266\n",
            "Epoch 14/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8434 - accuracy: 0.6224 - val_loss: 0.8398 - val_accuracy: 0.6257\n",
            "Epoch 15/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8434 - accuracy: 0.6226 - val_loss: 0.8396 - val_accuracy: 0.6246\n",
            "Epoch 16/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8433 - accuracy: 0.6225 - val_loss: 0.8391 - val_accuracy: 0.6248\n",
            "Epoch 17/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8433 - accuracy: 0.6228 - val_loss: 0.8386 - val_accuracy: 0.6261\n",
            "Epoch 18/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8433 - accuracy: 0.6222 - val_loss: 0.8396 - val_accuracy: 0.6243\n",
            "Epoch 19/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8433 - accuracy: 0.6228 - val_loss: 0.8384 - val_accuracy: 0.6273\n",
            "Epoch 20/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6226 - val_loss: 0.8399 - val_accuracy: 0.6254\n",
            "Epoch 21/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6227 - val_loss: 0.8387 - val_accuracy: 0.6238\n",
            "Epoch 22/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6226 - val_loss: 0.8391 - val_accuracy: 0.6274\n",
            "Epoch 23/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6229 - val_loss: 0.8385 - val_accuracy: 0.6269\n",
            "Epoch 24/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6230 - val_loss: 0.8387 - val_accuracy: 0.6275\n",
            "Epoch 25/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6226 - val_loss: 0.8393 - val_accuracy: 0.6242\n",
            "Epoch 26/100\n",
            "2146/2146 [==============================] - 15s 7ms/step - loss: 0.8432 - accuracy: 0.6230 - val_loss: 0.8408 - val_accuracy: 0.6266\n",
            "Epoch 27/100\n",
            "2041/2146 [===========================>..] - ETA: 0s - loss: 0.8429 - accuracy: 0.6230"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpXQHqr6xk0o"
      },
      "source": [
        "#Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87CY2a2-sIpT"
      },
      "source": [
        "prediction = model.predict(cv_valid)\n",
        "labels_val = ohe.inverse_transform(np.array(prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vupLGFy8iU3o",
        "outputId": "2aa39214-a107-4788-947c-8c4eaf5b37e7"
      },
      "source": [
        "print(\"Recall: \"+ str(recall_score(labels_valid, labels_val, average='macro')))\n",
        "print(\"Precision: \"+ str(precision_score(labels_valid, labels_val, average='macro')))\n",
        "print(\"F1: \"+ str(f1_score(labels_valid, labels_val, average='macro')))\n",
        "print(\"Accuracy: \"+ str(accuracy_score(labels_valid, labels_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.6326381215819751\n",
            "Precision: 0.6327334644511301\n",
            "F1: 0.632565416358763\n",
            "Accuracy: 0.6326966063808169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjQSDVKmzviv"
      },
      "source": [
        "Los resultados obtenidos cambiando los distintos parámetros se encuentran en un planilla adjunta al trabajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKcKqiRZyWEU"
      },
      "source": [
        "#Conclusiones\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tGG55psygPY"
      },
      "source": [
        "\n",
        "*   Para el modelo NB el preprocesamiento de tipo BOW (bag of words), que ignora la estructura de las frases y solo tiene en cuenta el significado de cada palabra individualmente y la cantidad de veces que aparece, no mejora el modelo. Esto puede indicar que el sesgo se encuentra en la estructura y no en el sentido de las palabras. \n",
        "*   Para el modelo NB, se obtuvieron mejores resultados con el vectorizador TFIDF que con Count Vectorizer.\n",
        "*   Al evaluar el modelo con los datos de train, se obtiene un accuracy más alto que con los datos de validación. No se alcanza una diferencia considerable como para detectar presencia de overfitting.\n",
        "*   Dado que el accuracy es razonablemente alto (entre 60% - 65%), se concluye que hay sesgos en el dataset (localizados en la estructura de los datos).\n",
        "*   En el modelo de NB el mejor resultado de accuracy que se obtuvo fue de 65,5761024182076, mientras que en el modelo de MLP se obtuvo un valor de 63,6151188782767. Los parámetros con los que se obtuvieron estos resultados se encuentran resaltados en las planillas adjuntas. \n",
        "*   Se esperaba un mejor resultado utilizando el modelo de MLP frente al de NB, ya que permite una mayor variación de parámetros y es un modelo mas complejo. Sin embargo, según los resultados obtenidos empíricamente hasta el momento esto no sucedió.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}